# Local AI vs Cloud AI Guide

> ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ AI ‡πÅ‡∏ö‡∏ö Local (Ollama) vs Cloud (Google Gemini)

---

## ü§î ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ‡πÉ‡∏ä‡πâ Local AI ‡πÅ‡∏ö‡∏ö Ollama ‡πÅ‡∏ó‡∏ô Google Gemini ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°?

**‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô:** **‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö!** ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ-‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤

---

## üìä ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Cloud AI vs Local AI

| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ | **Cloud AI (Gemini)** | **Local AI (Ollama)** |
|--------|---------------------|-------------------|
| **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å | ‚≠ê‚≠ê‚≠ê‚≠ê ‡∏î‡∏µ (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•) |
| **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß** | ‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å (Google servers) | üêå ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö hardware) |
| **‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô** | ~2,000-5,000 ‡∏ö‡∏≤‡∏ó | **‡∏ü‡∏£‡∏µ!** (‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á) |
| **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß** | ‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏á‡πÑ‡∏õ Google | ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á |
| **‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï** | ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 100% | ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ (offline ‡πÑ‡∏î‡πâ) |
| **‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° | ‚≠ê‚≠ê‚≠ê ‡∏î‡∏µ‡∏û‡∏≠‡πÉ‡∏ä‡πâ |
| **‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•** | N/A (‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà Google) | 4GB-70GB+ |
| **Setup ‡∏á‡πà‡∏≤‡∏¢** | ‚úÖ ‡πÅ‡∏Ñ‡πà API Key | ‚öôÔ∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á + config |

---

## ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á Local AI (Ollama)

### 1. **‡∏ü‡∏£‡∏µ - ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢ API**
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏à‡πà‡∏≤‡∏¢ Google/OpenAI
- ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î
- ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏¢‡∏≤‡∏ß

### 2. **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Privacy)**
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• SAR, ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô ‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£‡∏•‡∏±‡∏ö
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏á‡∏ß‡∏• data breach

### 3. **‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Offline ‡πÑ‡∏î‡πâ**
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏∂‡πà‡∏á‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏´‡πà‡∏≤‡∏á‡πÑ‡∏Å‡∏•

### 4. **‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà**
- Fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞ PMQA
- ‡∏õ‡∏£‡∏±‡∏ö parameters ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
- ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å rate limit

---

## ‚ùå ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏Ç‡∏≠‡∏á Local AI (Ollama)

### 1. **‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á Server**
- ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ GPU ‡∏ó‡∏µ‡πà‡πÅ‡∏£‡∏á (NVIDIA RTX 3090/4090 ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤)
- RAM ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 16GB (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 32GB+)
- ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ~80,000-200,000+ ‡∏ö‡∏≤‡∏ó

### 2. **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤**
- ‡πÇ‡∏°‡πÄ‡∏î‡∏• Open-source ‡πÑ‡∏°‡πà‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Gemini Pro/GPT-4
- ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏î‡∏µ‡πÄ‡∏ó‡πà‡∏≤
- ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

### 3. **‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ (‡∏ö‡∏ô Hardware ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤)**
- Inference time ‡∏≠‡∏≤‡∏à‡∏ô‡∏≤‡∏ô‡∏Å‡∏ß‡πà‡∏≤ Cloud AI
- ‡∏´‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏£‡∏á ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 10-30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ/‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö

### 4. **‡∏ï‡πâ‡∏≠‡∏á Maintain ‡πÄ‡∏≠‡∏á**
- ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏°‡πÄ‡∏î‡∏•
- ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ GPU memory
- Debug ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ

---

## üéØ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: Hybrid Approach

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î:** ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á Cloud AI ‡πÅ‡∏•‡∏∞ Local AI ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô

| ‡∏Å‡∏£‡∏ì‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ |
|-----------|------|
| **Chat with PMQA Rules** | üü¢ Local AI (Ollama) |
| **Smart Evidence Tagging** | üü¢ Local AI (Ollama) |
| **AI Writing Assistant** | üîµ Cloud AI (Gemini) |
| **SWOT Analysis** | üîµ Cloud AI (Gemini) |
| **Predictive Scoring** | üü¢ Local AI (Ollama/TensorFlow.js) |
| **OCR (‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏•‡∏±‡∏ö)** | üü¢ Local AI (Tesseract + fine-tuned) |
| **OCR (‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)** | üîµ Cloud AI (Google Vision) |

**‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:**
- ‚úÖ ‡πÉ‡∏ä‡πâ **Local AI** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏±‡∏ö, ‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢, ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ offline
- ‚úÖ ‡πÉ‡∏ä‡πâ **Cloud AI** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô, ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á, ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡∏ö‡πà‡∏≠‡∏¢

---

## üõ†Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows)

### 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama

```bash
# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å https://ollama.com/download/windows
# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ PowerShell
winget install Ollama.Ollama
```

### 2. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)

```bash
# Llama 3.1 8B (‡πÄ‡∏£‡πá‡∏ß, ‡πÉ‡∏ä‡πâ RAM ‡∏ô‡πâ‡∏≠‡∏¢)
ollama pull llama3.1:8b

# Mistral 7B (‡πÄ‡∏£‡πá‡∏ß, ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡∏µ)
ollama pull mistral:7b

# Qwen 2.5 14B (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
ollama pull qwen2.5:14b

# Llama 3.1 70B (‡πÅ‡∏°‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏ï‡πà‡∏ä‡πâ‡∏≤, ‡∏ï‡πâ‡∏≠‡∏á RAM 40GB+)
ollama pull llama3.1:70b
```

### 3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö

```bash
ollama run llama3.1:8b
# ‡∏û‡∏¥‡∏°‡∏û‡πå: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£
```

### 4. ‡∏£‡∏±‡∏ô Ollama ‡πÄ‡∏õ‡πá‡∏ô API Server

```bash
ollama serve
# API endpoint: http://localhost:11434
```

---

## üíª Integration ‡∏Å‡∏±‡∏ö Next.js App

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Code: ‡πÉ‡∏ä‡πâ Ollama ‡πÅ‡∏ó‡∏ô Gemini

#### **‡∏Å‡πà‡∏≠‡∏ô (Google Gemini):**

```typescript
// src/lib/ai/gemini.ts
import { GoogleGenerativeAI } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);
const model = genAI.getGenerativeModel({ model: 'gemini-pro' });

export async function chatWithPMQA(question: string) {
  const result = await model.generateContent(question);
  return result.response.text();
}
```

---

#### **‡∏´‡∏•‡∏±‡∏á (Ollama):**

```typescript
// src/lib/ai/ollama.ts
export async function chatWithPMQA(question: string) {
  const response = await fetch('http://localhost:11434/api/generate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: 'llama3.1:8b',
      prompt: question,
      stream: false,
    }),
  });

  const data = await response.json();
  return data.response;
}
```

---

#### **Hybrid: ‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á 2 ‡πÅ‡∏ö‡∏ö**

```typescript
// src/lib/ai/ai-service.ts
import { chatWithPMQA as ollamaChat } from './ollama';
import { chatWithPMQA as geminiChat } from './gemini';

const USE_LOCAL_AI = process.env.NEXT_PUBLIC_USE_LOCAL_AI === 'true';

export async function chatWithPMQA(question: string) {
  if (USE_LOCAL_AI) {
    return ollamaChat(question); // Local AI
  } else {
    return geminiChat(question); // Cloud AI
  }
}
```

**.env.local:**
```env
NEXT_PUBLIC_USE_LOCAL_AI=true  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô false ‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î
```

---

## üî• ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

| ‡πÇ‡∏°‡πÄ‡∏î‡∏• | ‡∏Ç‡∏ô‡∏≤‡∏î | RAM ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ | ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ | ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß |
|-------|------|--------------|--------|---------|
| **Llama 3.1:8B** | 4.7 GB | 8 GB | ‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å |
| **Mistral:7B** | 4.1 GB | 8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å |
| **Qwen 2.5:14B** | 9 GB | 16 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° ‡πÄ‡∏£‡πá‡∏ß |
| **Llama 3.1:70B** | 40 GB | 64 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö° ‡∏ä‡πâ‡∏≤ |

**‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:** `qwen2.5:14b` (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á)

---

## üìö RAG (Retrieval-Augmented Generation) ‡∏Å‡∏±‡∏ö PMQA

‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° PMQA ‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ **RAG**:

### 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Database

```bash
npm install @langchain/community chromadb
```

```typescript
// src/lib/ai/rag-setup.ts
import { ChromaClient } from 'chromadb';
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';
import { OllamaEmbeddings } from '@langchain/community/embeddings/ollama';

const client = new ChromaClient();
const collection = await client.createCollection('pmqa_rules');

// ‡πÅ‡∏¢‡∏Å PMQA documents ‡πÄ‡∏õ‡πá‡∏ô chunks
const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 500,
  chunkOverlap: 50,
});

const docs = await splitter.splitDocuments(pmqaDocuments);

// ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô ChromaDB
const embeddings = new OllamaEmbeddings({
  model: 'nomic-embed-text', // ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö embeddings
});

await collection.add({
  documents: docs.map(d => d.pageContent),
  embeddings: await Promise.all(docs.map(d => embeddings.embedQuery(d))),
  ids: docs.map((_, i) => `doc_${i}`),
});
```

### 2. Query ‡∏Å‡∏±‡∏ö Context

```typescript
// src/lib/ai/pmqa-chat.ts
export async function chatWithPMQARules(question: string) {
  // 1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
  const results = await collection.query({
    queryTexts: [question],
    nResults: 3,
  });

  const context = results.documents[0].join('\n\n');

  // 2. ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° + context ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Ollama
  const prompt = `
‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PMQA 4.0:

‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:
${context}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ${question}

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:`;

  const response = await fetch('http://localhost:11434/api/generate', {
    method: 'POST',
    body: JSON.stringify({
      model: 'qwen2.5:14b',
      prompt,
    }),
  });

  return (await response.json()).response;
}
```

---

## üí∞ ‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö (1 ‡∏õ‡∏µ)

### Cloud AI (Gemini)
```
‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: 100 ‡∏Ñ‡∏ô
‡πÉ‡∏ä‡πâ AI: 50 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á/‡∏Ñ‡∏ô/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô = 5,000 requests/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
‡∏£‡∏≤‡∏Ñ‡∏≤ Gemini Pro: $0.001 / 1,000 characters
‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: 500 chars output/request

= 5,000 √ó 500 chars = 2.5M chars/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
= $2.5/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô = ~90 ‡∏ö‡∏≤‡∏ó/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
= ~1,080 ‡∏ö‡∏≤‡∏ó/‡∏õ‡∏µ
```

‚úÖ **‡∏ñ‡∏π‡∏Å‡∏°‡∏≤‡∏Å** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö usage ‡∏ô‡πâ‡∏≠‡∏¢

---

### Local AI (Ollama)
```
‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á Server:
- RTX 4090 24GB: ~80,000 ‡∏ö‡∏≤‡∏ó
- RAM 64GB: ~15,000 ‡∏ö‡∏≤‡∏ó
- CPU/MB/Storage: ~30,000 ‡∏ö‡∏≤‡∏ó
= ‡∏£‡∏ß‡∏° ~125,000 ‡∏ö‡∏≤‡∏ó (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)

‡∏Ñ‡πà‡∏≤‡πÑ‡∏ü:
- 500W √ó 24‡∏ä‡∏° √ó 30‡∏ß‡∏±‡∏ô √ó 4 ‡∏ö‡∏≤‡∏ó/kWh = ~1,440 ‡∏ö‡∏≤‡∏ó/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
= ~17,280 ‡∏ö‡∏≤‡∏ó/‡∏õ‡∏µ

‡∏£‡∏ß‡∏°‡∏õ‡∏µ‡πÅ‡∏£‡∏Å: ~142,000 ‡∏ö‡∏≤‡∏ó
‡∏£‡∏ß‡∏°‡∏õ‡∏µ‡∏ó‡∏µ‡πà 2+: ~17,000 ‡∏ö‡∏≤‡∏ó/‡∏õ‡∏µ
```

‚úÖ **‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤** ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß

---

## üéØ ‡∏™‡∏£‡∏∏‡∏õ: ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô?

### ‡πÉ‡∏ä‡πâ **Cloud AI (Gemini)** ‡∏ñ‡πâ‡∏≤:
- ‚úÖ ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏à‡∏≥‡∏Å‡∏±‡∏î (‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≠‡∏¢)
- ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
- ‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ IT team ‡∏î‡∏π‡πÅ‡∏• server
- ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏±‡∏ö

### ‡πÉ‡∏ä‡πâ **Local AI (Ollama)** ‡∏ñ‡πâ‡∏≤:
- ‚úÖ ‡∏°‡∏µ‡∏á‡∏ö‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á server
- ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß 100%
- ‚úÖ ‡πÉ‡∏ä‡πâ AI ‡∏ö‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å (‡∏´‡∏•‡∏±‡∏Å‡∏û‡∏±‡∏ô-‡∏´‡∏°‡∏∑‡πà‡∏ô requests/‡∏ß‡∏±‡∏ô)
- ‚úÖ ‡∏°‡∏µ IT team ‡∏î‡∏π‡πÅ‡∏•
- ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ offline mode

### Hybrid (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥! üèÜ):
```
- Chat with PMQA Rules ‚Üí Ollama (‡∏ü‡∏£‡∏µ + ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢)
- Smart Tagging ‚Üí Ollama
- Writing Assistant ‚Üí Gemini (‡πÅ‡∏°‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤)
- Complex Analysis ‚Üí Gemini
```

---

## üìù ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (Proof of Concept)

1. **‡∏ó‡∏î‡∏•‡∏≠‡∏á Ollama ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á** (‡∏ü‡∏£‡∏µ)
   ```bash
   ollama run qwen2.5:14b
   ```

2. **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•** Ollama vs Gemini
   - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
   - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
   - ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

3. **‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à** ‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡πÑ‡∏´‡∏°

4. **‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡πâ‡∏°:** ‡∏à‡∏±‡∏î‡∏´‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á server + Deploy production

---

## üîó ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

- Ollama: https://ollama.com/
- LangChain: https://js.langchain.com/
- ChromaDB: https://www.trychroma.com/
- Hugging Face (Thai models): https://huggingface.co/models?language=th

---

**‡∏™‡∏£‡∏∏‡∏õ:** ‡πÉ‡∏ä‡πâ Local AI ‡πÑ‡∏î‡πâ‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô! ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ **Hybrid approach ‡∏à‡∏∞‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î** ‡∏Ñ‡∏£‡∏±‡∏ö üöÄ
